{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "289e0b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af613bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6575f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image original path exists: True\n",
      "Image mask path exists: True\n",
      "Label path exists: True\n",
      "CSV path exists: True\n"
     ]
    }
   ],
   "source": [
    "image_original_path = r\"C:/Users/ADMIN/Documents/ANkhe/v3_KaNak2_new/v3_KaNak2_new/KaNak2_new\"\n",
    "image_mask_path = r\"C:/Users/ADMIN/Documents/ANkhe/v3_KaNak2_new/v3_KaNak2_new/masks\"\n",
    "label_path = r\"C:/Users/ADMIN/Documents/ANkhe/v3_KaNak2_new/v3_KaNak2_new/annotations.xml\"\n",
    "csv_path = r\"C:/Users/ADMIN/Documents/ANkhe/KaNak.csv\"\n",
    "\n",
    "print(f\"Image original path exists: {os.path.exists(image_original_path)}\")\n",
    "print(f\"Image mask path exists: {os.path.exists(image_mask_path)}\")\n",
    "print(f\"Label path exists: {os.path.exists(label_path)}\")\n",
    "print(f\"CSV path exists: {os.path.exists(csv_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_cvat_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    recs = []\n",
    "    for img_el in root.findall(\".//image\"):\n",
    "        name = img_el.attrib[\"name\"]\n",
    "        w = int(float(img_el.attrib[\"width\"]))\n",
    "        h = int(float(img_el.attrib[\"height\"]))\n",
    "        objs = []\n",
    "        for poly in img_el.findall(\"polyline\"):\n",
    "            label = poly.attrib.get(\"label\", \"\")\n",
    "            pts = []\n",
    "            for p in poly.attrib.get(\"points\", \"\").split(\";\"):\n",
    "                p = p.strip()\n",
    "                if not p:\n",
    "                    continue\n",
    "                xs, ys = p.split(\",\")\n",
    "                pts.append((float(xs), float(ys)))\n",
    "            if len(pts) >= 2:\n",
    "                objs.append({\"label\": label, \"points\": pts})\n",
    "        recs.append({\"name\": name, \"width\": w, \"height\": h, \"objects\": objs})\n",
    "    return recs\n",
    "\n",
    "def polyline_to_mask(width, height, points, close=True, thickness=None):\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    pts = np.array(points, dtype=np.float32)\n",
    "    pts[:, 0] = np.clip(pts[:, 0], 0, width - 1)\n",
    "    pts[:, 1] = np.clip(pts[:, 1], 0, height - 1)\n",
    "    pts = np.round(pts).astype(np.int32)\n",
    "\n",
    "    if close:\n",
    "        if not (pts[0] == pts[-1]).all():\n",
    "            pts = np.vstack([pts, pts[0]])\n",
    "        cv2.fillPoly(mask, [pts], 255)\n",
    "    else:\n",
    "        if thickness is None: thickness = 2\n",
    "        cv2.polylines(mask, [pts], isClosed=False, color=255, thickness=thickness)\n",
    "    return mask\n",
    "\n",
    "def build_binary_mask(rec, target_labels=None, close=True, thickness=None):\n",
    "    w, h = rec[\"width\"], rec[\"height\"]\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    for obj in rec[\"objects\"]:\n",
    "        if (target_labels is None) or (obj[\"label\"] in target_labels):\n",
    "            m = polyline_to_mask(w, h, obj[\"points\"], close=close, thickness=thickness)\n",
    "            mask = np.maximum(mask, m)\n",
    "    return (mask > 0).astype(np.uint8)\n",
    "\n",
    "def load_masks_from_cvat_xml(xml_path, images_root=None, target_labels={\"lake\"}, target_size=(320,320)):\n",
    "    \"\"\"\n",
    "    Trả về:\n",
    "      masks: np.ndarray (N, H, W) đã resize về target_size và chuẩn hoá [0,1]\n",
    "      filenames: list[str] tên ảnh tương ứng trong XML\n",
    "    \"\"\"\n",
    "    recs = parse_cvat_xml(xml_path)\n",
    "\n",
    "    masks = []\n",
    "    names = []\n",
    "    for rec in recs:\n",
    "        mask_bin = build_binary_mask(rec, target_labels=target_labels, close=True)\n",
    "        mask_resized = cv2.resize(mask_bin, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        masks.append(mask_resized.astype(np.float32))  # 0/1\n",
    "        names.append(os.path.basename(rec[\"name\"]))\n",
    "    return np.stack(masks, axis=0), names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d860e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 32 masks from XML\n",
      "Mask array shape: (32, 320, 320)  # (N, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "mask_images, image_filenames = load_masks_from_cvat_xml(\n",
    "    xml_path=label_path,\n",
    "    # images_root=image_original_path,    \n",
    "    target_labels={\"lake\"},\n",
    "    target_size=(320, 320)\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(mask_images)} masks from XML\")\n",
    "print(f\"Mask array shape: {mask_images.shape}  # (N, 320, 320)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed30e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated images shape: (48, 1, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "def interpolate_images_to_monthly(images, target_months=48):\n",
    "    if len(images) >= target_months:\n",
    "        return images[:target_months]\n",
    "\n",
    "    interpolated = []\n",
    "    images_per_month = len(images) / 12.0\n",
    "\n",
    "    for month in range(target_months):\n",
    "        year = month // 12\n",
    "        month_in_year = month % 12\n",
    "\n",
    "        base_idx = int(month_in_year * images_per_month) % len(images)\n",
    "        base_image = images[base_idx].copy()\n",
    "\n",
    "        seasonal_noise = 0.05 * np.sin(2 * np.pi * month_in_year / 12)\n",
    "        noise = np.random.normal(0, 0.02, base_image.shape)\n",
    "\n",
    "        interpolated_image = np.clip(base_image + seasonal_noise + noise, 0, 1)\n",
    "        interpolated.append(interpolated_image)\n",
    "\n",
    "    return np.array(interpolated)\n",
    "\n",
    "interpolated_images = interpolate_images_to_monthly(mask_images, 48)\n",
    "interpolated_images = interpolated_images.reshape(-1, 1, 320, 320)\n",
    "print(f\"Interpolated images shape: {interpolated_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbe757a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series data shape: (35000, 12)\n",
      "Date range: 2019-01-01 03:00:00 to 2022-12-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df = df.sort_values('Time').reset_index(drop=True)\n",
    "\n",
    "df.columns = ['Time', 'WaterLevel_m', 'TotalDischarge_m3s', 'Inflow_m3s']\n",
    "\n",
    "df['Month'] = df['Time'].dt.month\n",
    "df['IsFloodSeason'] = ((df['Month'] >= 5) & (df['Month'] <= 10)).astype(int)\n",
    "\n",
    "for lag in [1, 2, 3]:\n",
    "    df[f'WaterLevel_lag{lag}'] = df['WaterLevel_m'].shift(lag)\n",
    "    df[f'Inflow_lag{lag}'] = df['Inflow_m3s'].shift(lag)\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(f\"Time series data shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Time'].min()} to {df['Time'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3025fadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\Documents\\ANkhe\\Pytorch-UNet\n"
     ]
    }
   ],
   "source": [
    "%cd Pytorch-UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c522681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from unet import UNet, DynamicSnake\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    \"\"\"Generalized Mean Pooling; p=1 -> GAP, p->inf -> GMP\"\"\"\n",
    "    def __init__(self, p: float = 3.0, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.tensor(p))\n",
    "        self.eps = eps\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.clamp(min=self.eps).pow(self.p)\n",
    "        return x.mean(dim=(-2, -1)).pow(1.0 / self.p)\n",
    "\n",
    "\n",
    "class UNetEDMSFeatureExtractor(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale features from BOTH encoder and decoder:\n",
    "      Encoder: x3, x4, x5\n",
    "      Decoder: d1, d2, d3, d4 (sau mỗi Up)\n",
    "\n",
    "    freeze_backbone=True + unfreeze_dynamic_snake=True:\n",
    "      - Đóng băng backbone ngoại trừ các tham số của DynamicSnake (alpha).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int = 1,\n",
    "        output_features: int = 1024,\n",
    "        n_classes: int = 2,\n",
    "        bilinear: bool = False,\n",
    "        freeze_backbone: bool = True,\n",
    "        unfreeze_dynamic_snake: bool = True,\n",
    "        use_encoder_stages = (\"x3\", \"x4\", \"x5\"),\n",
    "        use_decoder_stages = (\"d1\", \"d2\", \"d3\", \"d4\"),\n",
    "        act_type_enc: str = \"relu\",\n",
    "        act_type_dec: str = \"snake\",\n",
    "        **unet_kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unet = UNet(\n",
    "            n_channels=input_channels,\n",
    "            n_classes=n_classes,\n",
    "            bilinear=bilinear,\n",
    "            act_type_enc=act_type_enc,\n",
    "            act_type_dec=act_type_dec,\n",
    "            **unet_kwargs,\n",
    "        )\n",
    "\n",
    "        self.pool = GeM(p=3.0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, input_channels, 320, 320)\n",
    "            x1 = self.unet.inc(dummy)\n",
    "            x2 = self.unet.down1(x1)\n",
    "            x3 = self.unet.down2(x2)\n",
    "            x4 = self.unet.down3(x3)\n",
    "            x5 = self.unet.down4(x4)\n",
    "            d1 = self.unet.up1(x5, x4)\n",
    "            d2 = self.unet.up2(d1, x3)\n",
    "            d3 = self.unet.up3(d2, x2)\n",
    "            d4 = self.unet.up4(d3, x1)\n",
    "\n",
    "            ch = {\n",
    "                \"x3\": x3.shape[1], \"x4\": x4.shape[1], \"x5\": x5.shape[1],\n",
    "                \"d1\": d1.shape[1], \"d2\": d2.shape[1], \"d3\": d3.shape[1], \"d4\": d4.shape[1],\n",
    "            }\n",
    "\n",
    "        self.use_encoder_stages = tuple(use_encoder_stages)\n",
    "        self.use_decoder_stages = tuple(use_decoder_stages)\n",
    "\n",
    "        concat_dim = sum(ch[k] for k in self.use_encoder_stages) + \\\n",
    "                     sum(ch[k] for k in self.use_decoder_stages)\n",
    "\n",
    "        self.norm = nn.LayerNorm(concat_dim)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(concat_dim, 1024), nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, output_features), nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in self.unet.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            if unfreeze_dynamic_snake:\n",
    "                for m in self.unet.modules():\n",
    "                    if isinstance(m, DynamicSnake):\n",
    "                        for p in m.parameters():\n",
    "                            p.requires_grad = True\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x: torch.Tensor, return_dict: bool = False):\n",
    "        x1 = self.unet.inc(x)\n",
    "        x2 = self.unet.down1(x1)\n",
    "        x3 = self.unet.down2(x2)\n",
    "        x4 = self.unet.down3(x3)\n",
    "        x5 = self.unet.down4(x4)\n",
    "        d1 = self.unet.up1(x5, x4)\n",
    "        d2 = self.unet.up2(d1, x3)\n",
    "        d3 = self.unet.up3(d2, x2)\n",
    "        d4 = self.unet.up4(d3, x1)\n",
    "\n",
    "        feat = {\"x3\": x3, \"x4\": x4, \"x5\": x5, \"d1\": d1, \"d2\": d2, \"d3\": d3, \"d4\": d4}\n",
    "\n",
    "        zs = [self.pool(feat[k]) for k in self.use_encoder_stages]\n",
    "        zs += [self.pool(feat[k]) for k in self.use_decoder_stages]\n",
    "\n",
    "        z = torch.cat(zs, dim=1)\n",
    "        z = self.norm(z)\n",
    "        z = self.head(z)\n",
    "\n",
    "        if return_dict:\n",
    "            return z, feat\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d039f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "unet_model = UNetEDMSFeatureExtractor(\n",
    "    input_channels=1,\n",
    "    output_features=1024,\n",
    "    n_classes=2,\n",
    "    bilinear=False,\n",
    "    freeze_backbone=True,          # hoặc False nếu muốn fine-tune toàn bộ\n",
    "    unfreeze_dynamic_snake=True,   # để DynamicSnake còn học alpha\n",
    "    act_type_enc=\"relu\",\n",
    "    act_type_dec=\"relu\",\n",
    "    c3str_layers=2, c3str_heads=8, c3str_mlp_ratio=4, c3str_dropout=0.1\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dca1b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image features shape: (48, 1024)\n"
     ]
    }
   ],
   "source": [
    "def extract_image_features(model, images, batch_size=4):\n",
    "    model.eval()\n",
    "    feats = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch = torch.as_tensor(images[i:i+batch_size], dtype=torch.float32, device=device)\n",
    "            z = model(batch)\n",
    "            feats.append(z.cpu().numpy())\n",
    "    return np.vstack(feats)\n",
    "\n",
    "image_features = extract_image_features(unet_model, interpolated_images, batch_size=4)\n",
    "print(f\"Image features shape: {image_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d01e461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series features shape: (35000, 1024)\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_dim, output_features=1024):\n",
    "        super(TimeSeriesFeatureExtractor, self).__init__()\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, output_features),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc_layers(x)\n",
    "\n",
    "feature_columns = ['Inflow_m3s', 'TotalDischarge_m3s', 'IsFloodSeason',\n",
    "                  'WaterLevel_lag1', 'Inflow_lag1', 'WaterLevel_lag2',\n",
    "                  'Inflow_lag2', 'WaterLevel_lag3', 'Inflow_lag3']\n",
    "\n",
    "ts_feature_data = df[feature_columns].values\n",
    "ts_scaler = StandardScaler()\n",
    "ts_feature_data_scaled = ts_scaler.fit_transform(ts_feature_data)\n",
    "\n",
    "ts_model = TimeSeriesFeatureExtractor(len(feature_columns)).to(device)\n",
    "\n",
    "def extract_ts_features(model, data, batch_size=32):\n",
    "    model.eval()\n",
    "    features = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data), batch_size):\n",
    "            batch = data[i:i+batch_size]\n",
    "            batch_tensor = torch.FloatTensor(batch).to(device)\n",
    "            batch_features = model(batch_tensor)\n",
    "            features.append(batch_features.cpu().numpy())\n",
    "\n",
    "    return np.vstack(features)\n",
    "\n",
    "ts_features = extract_ts_features(ts_model, ts_feature_data_scaled)\n",
    "print(f\"Time series features shape: {ts_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "332e1e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded image features shape: (35000, 1024)\n"
     ]
    }
   ],
   "source": [
    "def expand_image_features_to_daily(image_features, n_days):\n",
    "    n_months = len(image_features)\n",
    "    days_per_month = n_days / n_months\n",
    "\n",
    "    expanded_features = []\n",
    "    for i, monthly_feature in enumerate(image_features):\n",
    "        start_day = int(i * days_per_month)\n",
    "        end_day = int((i + 1) * days_per_month)\n",
    "\n",
    "        for _ in range(end_day - start_day):\n",
    "            expanded_features.append(monthly_feature)\n",
    "\n",
    "    return np.array(expanded_features[:n_days])\n",
    "\n",
    "expanded_image_features = expand_image_features_to_daily(image_features, len(ts_features))\n",
    "print(f\"Expanded image features shape: {expanded_image_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8d572fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features shape: (35000, 2048)\n"
     ]
    }
   ],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "image_features_norm = feature_scaler.fit_transform(expanded_image_features)\n",
    "ts_features_norm = feature_scaler.fit_transform(ts_features)\n",
    "\n",
    "combined_features = np.concatenate([image_features_norm, ts_features_norm], axis=1)\n",
    "print(f\"Combined features shape: {combined_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea2de1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence shapes - X: (34996, 4, 2048), y: (34996,)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences_for_gru(features, labels, time_steps=4):\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(time_steps, len(features)):\n",
    "        X.append(features[i-time_steps:i])\n",
    "        y.append(labels[i])\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "labels = df['WaterLevel_m'].values\n",
    "min_len = min(len(combined_features), len(labels))\n",
    "combined_features = combined_features[:min_len]\n",
    "labels = labels[:min_len]\n",
    "\n",
    "X_seq, y_seq = create_sequences_for_gru(combined_features, labels, time_steps=4)\n",
    "print(f\"Sequence shapes - X: {X_seq.shape}, y: {y_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14db0dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 24497, Validation: 6999, Test: 3500\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.7 * len(X_seq))\n",
    "val_size = int(0.2 * len(X_seq))\n",
    "\n",
    "X_train = X_seq[:train_size]\n",
    "y_train = y_seq[:train_size]\n",
    "X_val = X_seq[train_size:train_size+val_size]\n",
    "y_val = y_seq[train_size:train_size+val_size]\n",
    "X_test = X_seq[train_size+val_size:]\n",
    "y_test = y_seq[train_size+val_size:]\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "baseline_ts_sequences, _ = create_sequences_for_gru(ts_features, labels, time_steps=4)\n",
    "baseline_X_train = baseline_ts_sequences[:train_size]\n",
    "baseline_X_val = baseline_ts_sequences[train_size:train_size+val_size]\n",
    "baseline_X_test = baseline_ts_sequences[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1101ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterLevelDataset(Dataset):\n",
    "    def __init__(self, sequences, targets, scaler_y=None, fit_scaler=False):\n",
    "        self.sequences = torch.FloatTensor(sequences)\n",
    "\n",
    "        if fit_scaler:\n",
    "            if scaler_y is None:\n",
    "                self.scaler_y = MinMaxScaler()\n",
    "            else:\n",
    "                self.scaler_y = scaler_y\n",
    "            targets_scaled = self.scaler_y.fit_transform(targets.reshape(-1, 1)).flatten()\n",
    "        elif scaler_y is not None:\n",
    "            self.scaler_y = scaler_y\n",
    "            targets_scaled = scaler_y.transform(targets.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            self.scaler_y = None\n",
    "            targets_scaled = targets\n",
    "\n",
    "        self.targets = torch.FloatTensor(targets_scaled)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.targets[idx]\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "train_dataset = WaterLevelDataset(X_train, y_train, scaler_y, fit_scaler=True)\n",
    "val_dataset = WaterLevelDataset(X_val, y_val, scaler_y)\n",
    "test_dataset = WaterLevelDataset(X_test, y_test, scaler_y)\n",
    "\n",
    "baseline_train_dataset = WaterLevelDataset(baseline_X_train, y_train, scaler_y)\n",
    "baseline_val_dataset = WaterLevelDataset(baseline_X_val, y_val, scaler_y)\n",
    "baseline_test_dataset = WaterLevelDataset(baseline_X_test, y_test, scaler_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "baseline_train_loader = DataLoader(baseline_train_dataset, batch_size=32, shuffle=True)\n",
    "baseline_val_loader = DataLoader(baseline_val_dataset, batch_size=32, shuffle=False)\n",
    "baseline_test_loader = DataLoader(baseline_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bd82b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models built\n",
      "Proposed model input shape: (34996, 4, 2048)\n",
      "Baseline model input shape: (34996, 4, 1024)\n"
     ]
    }
   ],
   "source": [
    "class ProposedGRUModel(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim=128, num_layers=2):\n",
    "        super(ProposedGRUModel, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(feature_dim, hidden_dim, num_layers,\n",
    "                         batch_first=True, dropout=0.2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        last_output = gru_out[:, -1, :]\n",
    "        output = self.dropout(last_output)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "class BaselineGRUModel(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim=64, num_layers=2):\n",
    "        super(BaselineGRUModel, self).__init__()\n",
    "\n",
    "        self.gru = nn.GRU(feature_dim, hidden_dim, num_layers,\n",
    "                         batch_first=True, dropout=0.2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(25, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        last_output = gru_out[:, -1, :]\n",
    "        output = self.dropout(last_output)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "proposed_model = ProposedGRUModel(X_seq.shape[2]).to(device)\n",
    "baseline_model = BaselineGRUModel(baseline_ts_sequences.shape[2]).to(device)\n",
    "\n",
    "print(\"Models built\")\n",
    "print(f\"Proposed model input shape: {X_seq.shape}\")\n",
    "print(f\"Baseline model input shape: {baseline_ts_sequences.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f913a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training proposed model...\n",
      "Epoch [10/50], Train Loss: 0.0000, Val Loss: 0.0001\n",
      "Epoch [20/50], Train Loss: 0.0000, Val Loss: 0.0001\n",
      "Epoch [30/50], Train Loss: 0.0000, Val Loss: 0.0001\n",
      "Epoch [40/50], Train Loss: 0.0000, Val Loss: 0.0001\n",
      "Epoch [50/50], Train Loss: 0.0000, Val Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=50, lr=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for sequences, targets in train_loader:\n",
    "            sequences, targets = sequences.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences).squeeze()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for sequences, targets in val_loader:\n",
    "                sequences, targets = sequences.to(device), targets.to(device)\n",
    "                outputs = model(sequences).squeeze()\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "print(\"Training proposed model...\")\n",
    "proposed_train_losses, proposed_val_losses = train_model(proposed_model, train_loader, val_loader)\n",
    "\n",
    "# print(\"Training baseline model...\")model(baseline_model, baseline_train_loader, baseline_val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5883ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions completed\n",
      "Predicted shapes - Proposed: (3500,), Baseline: (3500,)\n",
      "Actual test shape: (3500,)\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(model, test_loader, scaler_y):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, targets in test_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            outputs = model(sequences).squeeze()\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(targets.numpy())\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "\n",
    "    predictions_unscaled = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "    actuals_unscaled = scaler_y.inverse_transform(actuals.reshape(-1, 1)).flatten()\n",
    "\n",
    "    return predictions_unscaled, actuals_unscaled\n",
    "\n",
    "y_pred_proposed, y_test_actual = make_predictions(proposed_model, test_loader, scaler_y)\n",
    "y_pred_baseline, _ = make_predictions(baseline_model, baseline_test_loader, scaler_y)\n",
    "\n",
    "print(\"Predictions completed\")\n",
    "print(f\"Predicted shapes - Proposed: {y_pred_proposed.shape}, Baseline: {y_pred_baseline.shape}\")\n",
    "print(f\"Actual test shape: {y_test_actual.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c2ffb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE GRU MODEL RESULTS:\n",
      "MAE:  111.1228\n",
      "MSE:  12374.1572\n",
      "RMSE: 111.2392\n",
      "\n",
      "PROPOSED MODEL (unet + GRU) RESULTS:\n",
      "MAE:  2.7099\n",
      "MSE:  9.3517\n",
      "RMSE: 3.0581\n",
      "\n",
      "IMPROVEMENT OVER BASELINE:\n",
      "MAE improvement:  97.6%\n",
      "MSE improvement:  99.9%\n",
      "RMSE improvement: 97.3%\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse}\n",
    "\n",
    "proposed_metrics = calculate_metrics(y_test_actual, y_pred_proposed)\n",
    "baseline_metrics = calculate_metrics(y_test_actual, y_pred_baseline)\n",
    "\n",
    "mae_improvement = (baseline_metrics['MAE'] - proposed_metrics['MAE']) / baseline_metrics['MAE'] * 100\n",
    "mse_improvement = (baseline_metrics['MSE'] - proposed_metrics['MSE']) / baseline_metrics['MSE'] * 100\n",
    "rmse_improvement = (baseline_metrics['RMSE'] - proposed_metrics['RMSE']) / baseline_metrics['RMSE'] * 100\n",
    "\n",
    "print(\"BASELINE GRU MODEL RESULTS:\")\n",
    "print(f\"MAE:  {baseline_metrics['MAE']:.4f}\")\n",
    "print(f\"MSE:  {baseline_metrics['MSE']:.4f}\")\n",
    "print(f\"RMSE: {baseline_metrics['RMSE']:.4f}\")\n",
    "\n",
    "print(f\"\\nPROPOSED MODEL (unet + GRU) RESULTS:\")\n",
    "print(f\"MAE:  {proposed_metrics['MAE']:.4f}\")\n",
    "print(f\"MSE:  {proposed_metrics['MSE']:.4f}\")\n",
    "print(f\"RMSE: {proposed_metrics['RMSE']:.4f}\")\n",
    "\n",
    "print(f\"\\nIMPROVEMENT OVER BASELINE:\")\n",
    "print(f\"MAE improvement:  {mae_improvement:.1f}%\")\n",
    "print(f\"MSE improvement:  {mse_improvement:.1f}%\")\n",
    "print(f\"RMSE improvement: {rmse_improvement:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57415153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
